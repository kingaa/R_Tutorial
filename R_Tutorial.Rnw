\documentclass[12pt]{amsart}

%% NOTES:
%% Need to include pseudo-RNG functions, etc.

\input{labskel.tex}
\setcounter{tocdepth}{1}

\title{A Tutorial Introduction to \R}
\hypersetup{pdftitle={A Tutorial Introduction to R}}
\author[King]{Aaron A. King}
\address{Aaron A. King, Departments of Ecology \& Evolutionary Biology and Mathematics, University of Michigan}
\date{\today}
\thanks{
  This document has its origins in one created by Steve Ellner (Cornell University) and Ben Bolker (McMaster University).
  I have substantially modified and augmented it over many iterations.
  \raggedright Licensed under the Creative Commons attribution-noncommercial license, \texttt{http://creativecommons.org/licenses/by-nc/3.0/}.
  Please share and remix noncommercially, mentioning its origin \includegraphics[height=10pt]{cc-by-nc}}

<<include=FALSE>>=
library(knitr)
prefix <- "R_Tutorial"
opts_chunk$set(
               progress=T,prompt=F,tidy=F,highlight=T,
               warning=T,message=T,error=F,strip.white=T,cache=T,
               results='markup',echo=T,
               size='small',
               fig.lp="fig:",
               fig.path=paste0("figure/",prefix,"-"),
               cache.path=paste0("cache/",prefix,"-"),
               fig.align='left',
               fig.show='asis',
               fig.height=4,fig.width=6.83,
               out.width="\\linewidth",
               dpi=300,
               dev='png',
               dev.args=list(
                 png=list(bg='transparent'),
                 tiff=list(compression='lzw')
                 )
               )
@


\begin{document}

\maketitle

\tableofcontents

<<include=FALSE>>=
options(
        keep.source=TRUE,
        encoding="UTF-8"
        )
pdf.options(useDingbats=FALSE)
@ 

\section{How to use this document}

\begin{itemize}
\item These notes contain many sample calculations. 
  It is important to do these yourself---\textbf{type them in at your keyboard and see what happens on your screen}---to get the feel of working in \R. 
\item \textbf{Exercises} in the middle of a section should be done immediately when you get to them, and make sure you have them right before moving on. 
  Some more challenging exercises (indicated by asterisks or identified as a Project) are given at the end of some sections. 
  These can be left until later, and may be assigned as homework.   
\end{itemize}

Many other similar introductions are scattered around the web;
a partial list is in the ``contributed documentation'' section on the R web site (\url{http://cran.r-project.org/other-docs.html}). 
This particular version is limited (it has similar coverage to the \emph{Introduction to \R} that comes with \R) and targets biologists who are neither (yet) programmers nor statisticians.

\section{What is \R?}
\R\ is a computing environment that combines 
\begin{itemize}
\item a programming language called \Slang, developed by John Chambers at Bell Labs, that implements the idea of \emph{programming with data} \citep{Chambers1998},
\item an extensive set of functions for classical and modern statistical data analysis and modeling,
\item powerful numerical analysis tools for linear algebra, differential equations, and stochastics,
\item graphics functions for visualizing data and model output, 
\item a modular and extensible structure that supports a vast array of optional add-on packages, and
\item extensive help and documentation facilities.
\end{itemize}

\R\ is an open source project, available for free download via the Web \citep{R}.
Originally a research project in statistical computing \citep{Ihaka1996}, it is now managed by a development team that includes a number of well-regarded statisticians, and is widely used by statistical researchers and working scientists as a platform for making new methods available to users.  
The commercial implementation of \Slang\ (called \textsf{S-PLUS}) offers an Office-style ``point and click'' interface that \R\ lacks. 
The advantage of this front-end is outweighed by the fact that \R\ is free and open-source, built on a faster and much less memory-hungry implementation of \Slang\, and is easier to interface with other languages. 
A standard installation of of \R\ also includes extensive documentation, including an introductory manual ($\approx 100$ pages) and a comprehensive reference manual (over 1000 pages).  

There are a number of graphical front-ends for \R.
At present, the best of these appears to be \pkg{RStudio} (\url{http://www.rstudio.com}).
Before learning about these, however, you should learn a little about \R\ itself.
 
\section{Getting started with \R}

\subsection{Installing \R\ on your computer}

The main source for \R\ is the Comprehensive R Archive Network (CRAN): \url{http://cran.r-project.org}. 
You can get the source code and compile it yourself, but you may prefer at this point to download and install a precompiled version. 
You can download precompiled binaries for most major platforms from any CRAN mirror.
To do so:
\begin{itemize}
\item go to \url{http://cran.r-project.org/mirrors.html} and find a mirror site that is geographically somewhat near you.
\item Find the appropriate page for your operating system --- when you get to the download section, go to \code{base} rather than \code{contrib}.
Download the binary file (e.g. \code{base/R-x.y.z-win32.exe} for Windows, \code{R-x.y.z.dmg} for MacOS, where \code{x.y.z} is the version number).  
The binary files are large (30--60 megabytes) --- you will need to find a fast internet connection.
\item Read and follow the instructions.
\end{itemize}
\textbf{Be sure to install the latest version, which is \Sexpr{paste(R.version$major,R.version$minor,sep='.')}, nicknamed ``\Sexpr{R.version$nickname}''.}

\R\ should work well on any reasonably recent computer.

For Windows, \R\ is installed by launching the downloaded file and following the on-screen instructions. 
At the end you'll have an \R\ icon on your desktop that can be used to launch the program. 

\textbf{In the following, we've tried to mark Windows-specific items with a \windows\ and *nix (linux/unix/MacOSX)-specific items with a \nix.}

The standard distributions of \R\ include several \emph{packages}: user-contributed suites of add-on functions.  
These notes use some additional packages which you will have to install.
In the Windows version additional packages can be installed easily from within \R\ using the \textbf{Packages} menu.
Under all platforms, you can use the commands \code{install.packages()} and \code{update.packages()} to install and update packages, respectively.
Most packages are available pre-compiled for MacOS X and Windows;
under *nix, \R\ will download and compile the source code for you.

\subsection{Starting \R}

\nix\ Execute \code{R} from the command line.

\windows\ Click on the icon on your desktop, or in the \code{Start} menu (if you allowed the Setup program to make either or both of these).
If you lose these shortcuts for some reason, you can search for the executable file \code{Rgui.exe} on your hard drive, which will probably be somewhere like \verb+Program~Files\R\R-X.X.X\bin\Rgui.exe+.

\subsection{Stopping \R}

\begin{quotation}
  When entering, always look for the exit. ---Lebanese proverb
\end{quotation}

You can stop \R\ from the \code{File} menu (\windows), or you can stop it by typing \code{q()} at the command prompt (if you type \code{q} by itself, you will get some confusing output which is actually \R\ trying to tell you the definition of the \code{q} function; more on this later).

When you quit, \R\ will ask you if you want to save the workspace (that is, all of the variables you have defined in this session); 
in general, you should say ``no'' to avoid clutter and unintentional loading of old data.

Should an \R\ command seem to be stuck or take longer than you're willing to wait, click on the stop sign on the menu bar or hit the \code{Esc} key (\windows), or \code{Ctrl-c} (\nix).

\section{Interactive calculations}

When you start \R\ it opens the console window.
The console has a few basic menus at the top; check them out on your own. 
The console is also where you enter commands for \R\ to execute \emph{interactively}, meaning that the command is executed and the result is displayed as soon as you hit the \code{ Enter} key. 
For example, at the command prompt \code{>}, type in \code{2+2} and hit \code{Enter}; you will see 
<<>>=
2+2 
@

To do anything complicated, the results from calculations have to be stored in (\emph{assigned to}) variables. 
For example:
<<>>=
a <- 2+2
@
\R\ automatically creates the variable \code{a} and stores the result (\Sexpr{a}) in it, but \R\ doesn't print anything.  
This may seem strange, but you'll often be creating and manipulating huge sets of data that would fill many screens, so the default is to \emph{not} print the results.
To ask \R\ to print the value, just type the variable name by itself
<<>>=
a
@ 
The \code{[1]} at the beginning of the line is just \R\ printing an index of element numbers; if you print a result that displays on multiple lines, \R\ will put an index at the beginning of each line.  
\code{print(a)} also works to print the value of a variable.
By default, a variable created this way is a \emph{vector} (an ordered list), and it is \emph{numeric} because we gave \R\ a number rather than (e.g.) a character string like \code{"pxqr"}; in this case \code{a} is a numeric vector of length 1, which acts just like a number. 

You could also type \code{a <- 2+2; a}, using a semicolon to put two or more commands on a single line.
Conversely, you can break lines \textbf{anywhere that \R\ can tell you haven't finished your command} and \R\ will give you a ``continuation'' prompt (\code{+}) to let you know that it doesn't think you're finished yet: try typing
\begin{verbatim}
a <- 3*(4+
5)
\end{verbatim}
to see what happens (this often happens e.g. if you forget to close parentheses).
If you get stuck continuing a command you don't want---e.g., you opened the wrong parentheses---just hit \code{Ctrl-c} (\nix), the \code{Esc} key or the stop icon in the menu bar (\windows) to get out.

You can assign values to variables in \R\ using the \verb+<-+ operator.
There are several alternative forms for assignment.
Each of these three commands accomplishes the same thing; the first is the preferred form, however.
\begin{verbatim}
a <- 2+2
2+2 -> a
a = 2+2
\end{verbatim}

Variable names in \R\ must begin with a letter, followed by alphanumeric characters. 
You can break up long names with a period, as in \code{long.variable.number.3}, an underscore (\code{very\_very\_long\_variable\_name}), or by using camel case (\code{quiteLongVariableName}); 
you cannot use blank spaces in variable names. 
\R\ is case sensitive: \code{Abc} and \textsf{abc} are different variables.
Make variable names long enough to remember, short enough to type.
\code{N.per.ha} or \code{pop.density} are better than \code{x} and \code{y} (too short) or \code{available.nitrogen.per.hectare} (too long).
Avoid \code{c}, \code{l}, \code{q}, \code{t}, \code{C}, \code{D}, \code{F}, \code{I}, and \code{T}, which are either built-in \R\ functions or hard to tell apart.

\R\ does calculations with variables as if they were numbers. 
It uses \code{+}, \code{-}, \code{*}, \code{/}, and \verb!^! for addition, subtraction, multiplication, division and exponentiation, respectively. For example:
<<>>=
x <- 5
y <- 2
z1 <- x*y
z2 <- x/y
z3 <- x^y
z1; z2; z3
@ 

Even though \R\ did not display the values of \code{x} and \code{y}, it ``remembers'' that it assigned values to them. 
Type \verb! x; y ! or \verb! print(x); print(y) ! to display the values. 

You can retrieve and edit previous commands. 
The up-arrow (\thinspace $\uparrow$ \thinspace) key or \code{Ctrl-p} recalls previous commands to the prompt. 
For example, you can bring back the second-to-last command and edit it to
<<>>=
z3 <- 2*x^y
@ 
Experiment with the $\downarrow$, $\rightarrow$, $\leftarrow$, \code{Home} and \code{End} keys too.

You can combine several operations in one calculation:
<<>>=
A <- 3
C <- (A+2*sqrt(A))/(A+5*sqrt(A)); C
@ 

Parentheses specify the order of operations. 
The command
<<>>=
C <- A+2*sqrt(A)/A+5*sqrt(A)
@ 
is not the same as the one above; rather, it is equivalent to 
<<eval=FALSE>>=
C <- A + 2*(sqrt(A)/A) + 5*sqrt(A)
@ 
The default order of operations is: (1) parentheses, (2) exponentiation, (3) multiplication and division, (4) addition and subtraction.

\begin{tabular}{lcl}
\verb!> b <- 12-4/2^3! & gives  & \verb!12 - 4/8 = 12 - 0.5 = 11.5! \\
\verb!> b <- (12-4)/2^3! & gives & \verb!8/8 = 1! \\
\verb!> b <- -1^2!   &          gives  &  \verb!-(1^2) = -1! \\
\verb!> b <- (-1)^2! &          gives  &  \verb!1!
\end{tabular} 

In complicated expressions it's best to \textbf{use parentheses to specify explicitly what you want}, such as \verb! > b <- 12 - (4/(2^3)) ! or at least \verb! > b <- 12 - 4/(2^3) !; 
a few extra sets of parentheses never hurt anything, although if you get confused it's better to think through the order of operations rather than flailing around adding parentheses at random.

\R\ also has many \textbf{built-in mathematical functions} that operate on variables (\cref{MathFunctions} shows a few). 

\begin{exercise}
  Using editing shortcuts wherever you can, use \R\ to compute the values of 
  \begin{enumerate}
  \item $\frac{2^7}{2^7 - 1}$ and compare it with $( {1 - \frac{1}{2^7}} )^{-1}$
    (If any square brackets [] show up in your web browser, replace them with regular parentheses ().)
  \item 
    \begin{enumerate}
    \item $1+0.2$
    \item $1+0.2+0.2^2/2$
    \item $1+0.2+0.2^2/2+0.2^3/6$
    \item $e^{0.2}$ 
      (remembering that \R\ knows \code{exp()} but not $e$; how would you get \R\ to tell you the value of $e$?  
      What is the point of this exercise?)
    \end{enumerate}
  \item{the standard normal probability density, $\frac{1}{\sqrt{2 \pi}} e^{-x^2/2}$, for values of $x=1$ and $x=2$ (\R\ knows $\pi$ as \code{pi}.) 
    (You can check your answers against the built-in function for the normal distribution; \code{dnorm(x=c(1,2))} should give you the values for the standard normal for $x=1$ and $x=2$.)}
  \end{enumerate}
\end{exercise}

\section{The help system}

\R\ has a help system, although it is generally better for providing detail or reminding you how to do things than for basic ``how do I \ldots?'' questions.

\begin{itemize}
\item You can get help on any \R\ function by entering
\begin{verbatim}
?foo
\end{verbatim} 
(where \code{foo} is the name of the function you are interested in)
in the console window (e.g., try \code{?sin}). 
\item \windows\ The `Help' menu on the tool bar
provides links to other documentation,
including the manuals and FAQs, and a 
Search facility (`Apropos' on the menu)
which is useful if you sort of maybe remember part of the
the name of what it is you need help on.
\item Typing \code{help.start()}
opens a web browser with help information.
\item \code{example(cmd)} will run any examples that are included
in the help page for command \code{cmd}.
\item{\code{demo(topic)} runs demonstration code on topic \code{topic}: type
\code{demo()} by itself to list all available demos}
\end{itemize}

By default, \R's help system only provides information about functions that are in the base system and packages that you have loaded with \code{library} (see below).
\begin{itemize}
\item \code{??topic} or \code{help.search("topic")} 
  (with quotes)
will list information related to \code{topic} available in the base system or in any extra installed packages:
then use \code{?topic} to see the information, perhaps using
\code{library(pkg)} to load the appropriate package first.
\code{help.search} uses ``fuzzy matching'' --- for example, 
\code{help.search("log")} finds 528 entries (on my
particular system) including lots of
functions with ``plot'', which includes the letters ``lot'', which
are \emph{almost} like ``log''.  If you can't stand it, you
can turn this behavior off by specifying the incantation
\code{help.search("log",agrep=FALSE)} (81 results which still include
matches for ``logistic'', ``myelogenous'', and ``phylogeny'' \ldots)
\item \code{help(package="pkg")} will list all the help pages for
a loaded package.
\item \code{example(fun)} will run the examples (if any) given
  in the help for a particular function \code{fun}: e.g., \code{example(log)}
\item \code{RSiteSearch("topic")} does a full-text
  search of all the \R\ documentation and the mailing list archives
  for information on \code{topic} (you need an active
  internet connection).  
\item the \code{sos} package is a web-aware help function that
  searches all of the packages on CRAN; its \code{findFn} function
  tries to find and organize functions in any package on CRAN that
  match a search string (again, you need a network connection for this).
\end{itemize}

Try out one or more of these aspects of the help system.

% Finally, here's a commentary on the
% help system in \R\ from Graham Lawrence:
% \begin{quote}
% \small
% I hate to say this, but what really helped me the most, after the initial
% feet-wetting, was to abandon the help manuals.  Searching manuals for the
% answer to a specific question is frustrating because one does not know the
% key term for the search engine to deliver the item needed.

% So I stopped being serious and production oriented and simply played with \R\ 
% for a couple of months.  Open the Base package, scan the list of contents
% for titles that pique my curiosity, paste their examples into \R\ and see what
% happens.  And those examples use other functions and their documentation has
% more examples and so on and on; and pretty soon after, whoops, there's
% another afternoon gone down the tubes.  But all this apparent time wasting
% had a most happy result.  I now find, much more often than not, that I know
% what I need to look up to answer a specific question, and that does wonders
% for my disposition.

% I think of \R\ as a vast jungle, criss-crossed with myriad game trails (the
% documentation to each function in the packages).  And I can explore each
% trail and see what animal it leads to in its native habitat, by pasting the
% examples into \R\ and examining the result.  So when I see an interesting
% spoor or paw print, I take a stroll down that trail and see where it leads.
% Not the most efficient way of learning the language, no doubt, but a
% pleasant and interesting entertainment rather than a chore.
% \end{quote}

\paragraph{Other help resources}

\begin{itemize}
\item R reference card: \url{http://cran.r-project.org/doc/contrib/Short-refcard.pdf}
\item Paul Johnson's ``R tips'' web page (\url{http://pj.freefaculty.org/R/Rtips.html}) answers a number of ``how do I \ldots ?'' questions.
\item contributed documentation at CRAN: \url{http://cran.us.r-project.org/other-docs.html}
\item R ecology (``environmetrics'') task view: \url{http://cran.r-project.org/web/views/Environmetrics.html}
\end{itemize}


\begin{exercise}
  Do an Apropos on \code{sin} to see what it does. 
  Now enter the command
<<eval=FALSE>>=
help.search("sin")
@
and see what that does (answer: \code{help.search} pulls up all help pages that include `sin' anywhere in their title or text. 
Apropos just looks at the name of the function).
Note that \verb!??sin! is equivalent to \verb!help.search("sin")!.
If you have a net connection, try \verb+RSiteSearch("sin")+ from the command line or the equivalent from the menu and see what happens. 
\end{exercise}

\begin{table}[t]
\begin{tabular}{p{140pt}p{290pt}}
\hline
\code{abs()} & absolute value \\
\code{cos()}, \code{sin()}, \code{tan()} &  cosine, sine, tangent of angle x in radians\\
\code{exp()}  & exponential function, $e^x$  \\
\code{log()}  & natural (base-$e$) logarithm \\
\code{log10()} &  common (base-10) logarithm \\
\code{sqrt()}  &  square root \\
\hline 
\end{tabular}
\caption{Some of the built-in mathematical functions in \R. 
You can get a more complete list from the help system: 
\code{?Arithmetic} for simple, \code{?log} for logarithmic, \code{?sin} for trigonometric, and \code{?Special} for special functions.} 
\label{MathFunctions}
\end{table}


\section{A first interactive session: descriptive statistics}

Below are some data on the maximum growth rate $r_{\text{max}}$ of laboratory populations of the green alga \emph{Chlorella vulgaris} as a function of light intensity ($\mu$E per m$^2$ per second). 
These experiments were run during the system-design phase of the study reported by \citet{Fussman2000}.

Light: 20,  20,  20,  20,  21,  24,  44,  60,  90,  94, 101 \\
$r_{\text{max}}$: 1.73, 1.65, 2.02, 1.89, 2.61, 1.36, 2.37, 2.08, 2.69, 2.32, 3.67 \\

To analyze these data in \R, first enter them as numerical \emph{vectors}: 
<<>>=
Light <- c(20,20,20,20,21,24,44,60,90,94,101)
rmax <- c(1.73,1.65,2.02,1.89,2.61,1.36,2.37,2.08,2.69,2.32,3.67)
@ 
The function \code{c()} \emph{combines} the individual numbers into 
a vector.  Try recalling (with $\uparrow$) and modifying the above command to 
% don't try to weave, error stops things (even eval=FALSE doesn't help)
<<eval=FALSE>>=
Light <- 20,20,20,20,21,24,44,60,90,94,101
@ 
and see the error message you get: 
in order to create a vector of specified numbers, you must use the \code{c()} function.

To see a histogram of the growth rates enter \verb!hist(rmax)!, which opens a graphics window and displays the histogram. 
There are \textbf{many} other built-in statistics functions in \R.
Some of the most commonly used are shown in Table~\ref{tab:desc-stats}.
Play around with these functions, and any others you can think of.

\begin{table}[t]
\begin{tabular}{p{140pt}p{290pt}}
\hline
\code{mean(x)} & the arithmetic mean of the data in \code{x} \\
\code{exp(mean(log(x)))} & the geometric mean of \code{x}\\
\code{1/mean(1/x)} & the harmonic mean of \code{x}\\
\code{median(x)} & the median of \code{x}\\
\code{min(x)}, \code{max(x)} & the minimum and maximum, respectively, of \code{x}\\
\code{range(x)} & the range of \code{x}\\
\code{sd(x)} & the standard deviation of \code{x}\\
\code{var(x)} & the variance of \code{x}\\
\code{quantile(x, p)} & the \code{p}-th quantiles of \code{x}\\
\hline 
\end{tabular}
\caption{Some functions for descriptive statistics in \R. 
  \label{tab:desc-stats}}
\end{table}

To see how the algal rate of increase varies with light intensity, type
<<eval=F>>=
plot(Light,rmax)
@ 
to plot \code{rmax} ($y$) against \code{Light} ($x$).
Based on what you see, does it seem reasonable to hypothesize a linear relationship between these variables?

\section{Linear regression}

To perform linear regression we create a linear model using the \code{lm()} function:
<<>>=
fit <- lm(rmax~Light)
@ 
(Note that the variables in the formula \code{rmax~Light} appear in an order \emph{opposite} to that in \code{plot()} command above.
In the formula, \code{rmax} is the response variable and \code{Light} is the predictor.)

The \code{lm} command created an \emph{object} named \code{fit}.
In \R, an \emph{object} is a data structure consisting of multiple parts.
In this case, \code{fit} holds the results of the linear regression analysis. 
Unlike most statistics packages, \R\ rarely summarizes an analysis for you by default.
Statistical analyses in \R\ are done by creating a model, and then giving additional commands to extract desired information about the model or display results graphically.

To get a summary of the results, enter the command \code{summary(fit)}. 
\R\ sets up model objects (more on this later) so that the function \code{summary()} ``knows'' that \code{fit} was created by \code{lm()}, and produces an appropriate summary of results for an \code{lm()} object: 
<<>>=
summary(fit)
@ 

If you've had (and remember) a statistics course the output will make sense to you. 
The table of coefficients gives the estimated regression line as $\text{\code{rmax}} = \Sexpr{signif(coef(fit)[1],3)} + \Sexpr{signif(coef(fit)[2],3)} \times \text{\code{Light}}$.
Associated with each coefficient is the standard error of the estimate, the $t$-statistic value for testing whether the coefficient is nonzero, and the $p$-value corresponding to the $t$-statistic. 
Below the table, the adjusted $R^2$ gives the estimated fraction of the variance explained by the regression line, and the $p$-value in the last line is an overall test for significance of the model against the null hypothesis that the response variable is independent of the predictors.

You can add the regression line to the plot of the data with a function taking \code{fit} as its input (if you closed the plot of the data, you will need to create it again in order to add the regression line):
<<eval=FALSE>>=
abline(fit)
@
(\code{abline}, pronounced ``a b line'', is a general-purpose function for adding lines to a plot: you can specify horizontal or vertical lines, a slope and an intercept, or a regression model: \code{?abline}). 

\begin{figure}
\begin{center}
<<echo=FALSE,fig.width=8,fig.height=6>>=
plot(Light,rmax)
abline(fit)
@  
\end{center}
\label{Intro1.Fig1}
\caption{Graphical summary of regression analysis}
\end{figure}

You can get the coefficients by using the \code{coef()} function:
<<>>=
coef(fit)
@ 

You can also also ``interrogate'' \code{fit} directly. 
Type \code{names(fit)} to get a list of the components of \code{fit},
and then extract components according to their names
using the \verb!$! symbol.
<<>>=
names(fit)
@ 
You can get the regression coefficients this way:
<<>>=
fit$coefficients
@ 
It's good to be able to look inside \R\ objects when necessary, but all other things being equal you should prefer (e.g.) \code{coef(x)} to \verb+x$coefficients+.
For more information (perhaps more than you want) about \code{fit}, use \code{str(fit)} (for \textbf{str}ucture).

\section{Statistics in \R}

Some of the important functions and packages (collections of functions) for statistical modeling and data analysis are summarized in \cref{StatModelingFunctions}. 
The book \emph{Modern Applied Statistics with S} \citep{Venables2002} gives a good practical overview, and a list of available packages and their contents can be found at the main \R\ website (\url{http://cran.r-project.org}, and click on \code{Packages}). 

\begin{table}[t]
\begin{tabular}{p{140pt}p{290pt}}
\hline
\code{aov}, \code{anova} & Analysis of variance or deviance\\
\code{lm} & Linear models (regression, ANOVA, ANCOVA) \\
\code{glm} &  Generalized linear models (e.g. logistic, Poisson regression) \\
\code{gam} & Generalized additive models (in package \code{mgcv}) \\
\code{nls} & Fit nonlinear models by least-squares\\
\code{lme}, \code{nlme} & Linear and nonlinear mixed-effects models (repeated
measures, block effects, spatial models): in package \code{nlme} \\
\code{boot} & Package: bootstrapping functions \\
\code{splines}  &  Package: nonparametric regression (more in packages
        \code{fields}, \code{KernSmooth}, \code{logspline}, \code{sm} and others)\\
\code{princomp}, \code{manova}, \code{lda}, \code{cancor}
 & Multivariate analysis
(some in package \code{MASS};
also see packages \code{vegan}, \code{ade4}) \\
\code{survival} & Package: survival analysis \\
\code{tree}, \code{rpart} & Packages: tree-based regression \\
\hline 
\end{tabular}
\caption{A few of the functions and packages in \R\ for statistical
modeling and data analysis. There are \textbf{many} more, but you will have
to learn about them somewhere else. } 
\label{StatModelingFunctions}
\end{table}

\section{The \R\ package system}

\R\ has many extra packages that provide extra functions.  
You may be able to install new packages from a menu within \R. 
You can always type, e.g.,
<<eval=FALSE>>=
install.packages("plotrix")
@
This installs the \code{plotrix} package.
You can install more than one package at a time:
<<eval=FALSE>>=
install.packages(c("ellipse","plotrix"))
@
(\code{c} stands for ``combine'', and is the command for combining multiple things into a single object.)
If the machine on which you use \R\ is not connected to the
Internet, you can download the packages to some other medium
(such as a flash drive or CD)
and install them later, using \code{Install from local zip file}
in the menu (\windows) or
<<eval=FALSE>>=
install.packages("plotrix",repos=NULL)
@ 

If you do not have permission to install packages in \R's central directory, \R\ will
may ask whether you want to install the packages in a user-specific directory.
It is safe to answer ``yes'' here.

You will frequently get a warning message something like
\begin{verbatim}
Warning message: In file.create(f.tg) :
cannot create file '.../packages.html', reason 'Permission denied'.
\end{verbatim}
Don't worry about this; it means the package has been installed successfully,
but the main help system index files couldn't be updated
because of file permissions problems.

\section{Vectors} 

The most basic data-type in \R\ is the vector.
A vector is just a 1-dimensional array of values.
Several different kinds of vectors are available:
\begin{inparaenum}
  \item numerical vectors,
  \item logical vectors,
  \item character-string vectors,
  \item factors,
  \item ordered factors, and
  \item lists.
\end{inparaenum}
Lists are treated a bit differently in \R\ than the other kinds, so we'll postpone talking about them until later.

Besides its \emph{class}---which kind of vector it is---a vector's only other necessary attribute is its length.
Optionally, vectors in \R\ can have a \code{names} attribute, which allows you to refer to entries by name.

We've already how to create vectors in \R\ using the \code{c} function, e.g.,
<<>>=
x <- c(1,3,5,7,9,11)
y <- c(6.5,4.3,9.1,-8.5,0,3.6)
z <- c("dog","cat","dormouse","chinchilla")
w <- c(a=4,b=5.5,c=8.8)
<<>>=
length(x)
mode(y)
mode(z)
names(w)
@ 

The nice thing about having vectors as a basic type is that many operations in \R\ are efficiently \emph{vectorized}.
That is, the operation acts on the vector as a unit, saving you the trouble of treating each entry individually.
For example:
<<>>=
x <- x+1
xx <- sqrt(x)
x; xx
@ 

Notice that the operations were applied to every entry in the vector. 
Similarly, commands like \code{x-5, 2*x, x/10}, and \verb!x^2! apply subtraction, multiplication, and division to each element of the vector. 
The same is true for operations involving multiple vectors:
<<>>=
x+y
@ 

\begin{exercise}
  What do the \verb!%%! and \verb!%/%! operators do?
\end{exercise}

In \R\ the default is to apply functions and operations to vectors
in an \emph{element by element} manner; 
anything else (e.g. matrix multiplication) is done using special notation (discussed below). 

\subsubsection*{Warning: element recycling}
\R\ has a very useful, but unusual and perhaps unexpected, behavior when two vector operands in a vectorized operation are of unequal lengths.
It will effectively extend the shorter vector using element ``re-cycling'': 
re-using elements of the shorter vector.
Thus
<<>>=
x <- c(1,2,3)
y <- c(10,20,30,40,50,60)
x+y
y-x
@ 

\begin{exercise}
  What happens when the length of the longer vector is not a multiple of that of the shorter?
\end{exercise}

\subsection{Functions for creating vectors}

A set of regularly spaced values can be created with the \code{seq} function, whose syntax is \code{x~<-~seq(from,to,by)} or \code{x~<-~seq(from,to)} or \code{x~<-~seq(from,to,length.out)}.  
The first form generates a vector \code{(from,from+by,from+2*by,...)} with the last entry not extending further than than \code{to}; 
in the second form the value of \code{by} is assumed to be 1 or -1, depending on whether \code{from} or \code{to} is larger; 
and the third form creates a vector with the desired endpoints and length.
There is also a shortcut for creating vectors with \code{by=1}:
<<>>=
1:8
@

\begin{exercise}
  Use \code{seq} to create the vector \code{v=(1 5 9 13)}, and to create a vector going from 1 to 5 in increments of 0.2 . 
\end{exercise}

\begin{exercise}
  What happens when \code{to} is less than \code{from} in \code{seq}?
  This is one of the first ``gotchas'' \R\ newbies run into.
\end{exercise}

A constant vector such as \code{(1 1 1 1)} can be created with \code{rep} function, whose basic syntax is \verb! rep(values,lengths) !.  
For example,
<<>>=
rep(3,5)
@ 
creates a vector in which the value 3 is repeated 5 times. 
\code{rep()} will repeat a whole vector multiple times
<<>>=
rep(1:3,3)
@
or will repeat each of the elements in a vector a given number of times:
<<>>=
rep(1:3,each=3)
@
Even more flexibly, you can repeat each element in the vector a different number of times:
<<>>=
rep(c(3,4),c(2,5))
@ 
The value 3 was repeated 2 times, followed by the value 4 repeated 5 times.
\code{rep()} can be a little bit mind-blowing as you get started, but you'll get used to it---and it will turn out to be useful.

Some useful functions for creating and working with vectors are listed in \Cref{tab:VectorFunctions}. 

\begin{table}[t]
\begin{tabular}
{p{2.5in}p{3.75in}}
\hline
\code{seq(from,to,by=1)} & Vector of evenly spaced values (default increment = 1) \\
\code{seq(from, to, length.out)} & Vector of evenly spaced values, specified length \\
\code{c(u,v,...) } & Combine a set of numbers and/or vectors into a single vector \\
\code{rep(a,b)} & Create vector by repeating elements of \code{a} \code{b} times each\\
\code{hist(v)} & Histogram plot of value in v \\
\code{mean(v),var(v),sd(v)} & Estimate of population
mean, variance, standard deviation based on data values in \code{v} \\
\code{cov(v,w)} & Covariance between two vectors \\
\code{cor(v,w)} & Correlation between two vectors \\
\hline
\end{tabular}
\caption{Some important \R\ functions for creating and working with vectors. 
  Many of these have other optional arguments; use the help system (e.g. \code{?cor}) for more information. 
  The statistical functions such as \code{var} regard the values as samples from a population and compute an estimate of the population statistic; for example \code{sd(1:3)=1}.}
\label{tab:VectorFunctions}
\end{table}

\subsection{Vector indexing}

It is often necessary to extract a specific entry or other part of a vector. 
This procedure is called \emph{vector indexing}, and uses square brackets ([]):
<<>>=
  z <- c(1,3,5,7,9,11); z[3]
@ 
[How would you use \code{seq()} to construct \code{z}?]
\code{z[3]} extracts the third item, or \emph{element}, in the vector \code{z}. 
You can also access a block of elements by giving a vector of indices:
<<>>=
v <- z[c(2,3,4,5)]
@ 
or
<<>>=
v <- z[2:5]; v
@ 
This has extracted the 2\textsuperscript{nd} through 5\textsuperscript{th} elements in the vector. 
\begin{exercise}
  If you enter \code{v~<-~z[seq(1,5,2)]}, what will happen? 
  Make sure you understand why.
\end{exercise}

Extracted parts of a vector don't have to be regularly spaced. For example
<<>>=
v <- z[c(1,2,5)]; v
@ 

Indexing is also used to \textbf{set specific values within a vector}. 
For example, 
<<>>=
z[1] <- 12
@ 
changes the value of the first entry in \code{z} while leaving all the rest alone, and 
<<>>=
z[c(1,3,5)] <- c(22,33,44)
@ 
changes the 1\textsuperscript{st}, 3\textsuperscript{rd}, and 5\textsuperscript{th} values.  

Elements in a named vector can be accessed and modified by name as well as by position.
Thus
<<>>=
w
w["a"]
w[c("c","b")]
w["b"] <- 0
w
@ 


\begin{exercise}
  Write a \emph{one-line} command to extract a vector consisting of the second, first, and third elements of \code{z} \emph{in that order}. 
\end{exercise}

\begin{exercise}
  What happens when I set the value of an element that doesn't exist?
  For example, try
  <<eval=F>>=
  z[9] <- 11
  @   
\end{exercise}

% You may be wondering if vectors in \R\ 
% are row vectors or column vectors (if you don't know what those are,
% don't worry). The answer is ``both and neither''.
% Vectors are printed out as row vectors, but if you use a vector in 
% an operation that succeeds or fails depending on the vector's orientation, 
% \R\ will assume that you want the operation to succeed and will proceed as 
% if the vector has the necessary orientation. For example, \R\ will let
% you add a vector of length 5 to a $5 \times 1$ matrix or to a 
% $1 \times 5$ matrix, in either case yielding a matrix of the 
% same dimensions.

\begin{exercise}
  Write code that computes values of $y=\frac{(x-1)}{(x+1)}$ for $x=1,2,\cdots,10$, and plots $y$ versus $x$ with the points plotted and connected by a line. 
\end{exercise}

\subsubsection{Warning: unavoidable imprecision}

Note that comparing very similar numeric values can be tricky: rounding can happen, and some numbers cannot be represented exactly on a digital computer.  
By default, \R\ displays 7~significant digits (\code{options("digits")}). 
<<>>=
x <- 1.999999; x; x-2
x <- 1.9999999999999; x; x-2
x <- 1.99999999999999999; x; x-2
@ 
All the digits are still there, in the second case, but they are not shown.
Also note that \code{x-2} is not exactly $-1 \times 10^{-13}$; this is unavoidable.
What happened in the third case?

\begin{exercise}
The sum of the geometric series $1 + r + r^2 + r^3 + ... + r^n$ 
approaches the limit $1/(1-r)$ for $r < 1$ as $n \rightarrow \infty$.   
Take $r=0.5$ and $n=10$, and write a \textbf{one-line} command that creates 
the vector $G = (r^0,r^1,r^2,...,r^n)$. Compare the sum (using \code{sum()})
of this vector to the limiting value $1/(1-r)$. Repeat for  
$n=50$.  
\end{exercise}

\subsection{Logical operations}

Some operations return a logical value (i.e., \code{TRUE} or \code{FALSE}). 
For example, try:  
<<>>=
a <- 1; b <- 3; 
c <- a < b
d <- (a > b)
c; d
@ 
The parentheses around \verb+a > b+ above are optional but do make
the code easier to read.
Be careful when you make comparisons with negative values:
\verb+a<-1+ may surprise you by setting \code{a=1},
because \code{<-} is the assignment operator in \R.
Use \verb+a< -1+ or \verb+a<(-1)+ to make this comparison.

\begin{table} [t]
\begin{tabular}{p{120pt}p{200pt}}
\hline
x $<$ y  & less than    \\
x $>$ y  & greater than \\
x $<=$ y & less than or equal to \\
x $>=$ y & greater than or equal to \\
x $==$ y & equal to \\
x $!=$ y & \emph{not} equal to \\
\hline 
\end{tabular}
\caption{Some comparison operators in \R. Use \code{?Comparison} to learn more.}
\label{tab:Comparisons}
\end{table}

When we compare two vectors or matrices, comparisons are done element-by-element (and the recycling rule applies).
For example,
<<>>=
x <- 1:5; b <- (x<=3); b
@ 
So if \code{x} and \code{y} are vectors, then \code{(x==y)} will return a vector of values giving the element-by-element comparisons. 
If you want to know whether \code{x} and \code{y} are identical vectors, use \code{identical(x,y)} or \code{all.equal(x,y)}. 
You can use \code{?Logical} to read more about logical operations. 
\textbf{Note the difference between = and ==: can you figure out what happened in the following cautionary tale?}
<<>>=
a=1:3
b=2:4
a==b
a=b
a==b
@

% (Sometimes this kind of mistake is caught: if you tried to say
% \verb+if(a=b) print("yes")+ (which is supposed to do something if
% \code{a} is equal to \code{b}), \R\ would knows that something was wrong
% and would respond with an errror.)

Exclamation points \verb+!+ are used in \R\ to signify logical negation;
\verb+!=+ (not \verb+!==+) means ``not equal to''.

\R\ also does arithmetic on logical values, treating \code{TRUE} as 1 and \code{FALSE} as 0. So \verb!sum(b)! returns the value 3, telling us that three entries of \code{x} satisfied the condition (\verb+x<=3+). 
This is useful for (e.g.) seeing how many of the elements of a vector are larger than a cutoff value.

More complicated conditions are built by using \textbf{logical operators} to combine comparisons:\\
\begin{tabular}{cl}
\code{!} &   logical NOT  \\
\verb!&! &   logical AND, elementwise  \\
\verb!&&! &  logical AND, first element only  \\
\verb!|! &   logical OR, elementwise \\ 
\verb!||! &  logical OR, first element only \\
\verb!xor(x,y)! & exclusive OR, elementwise \\
\end{tabular}

The two forms of logical OR (\verb!|! and \verb!||!) are \emph{non-exclusive}, meaning that \code{x|y} is true if either \code{x} or \code{y} or both are true. 
For example, try
<<>>=
a <- c(1,2,3,4)
b <- c(1,1,5,5)
(a<b) & (a>3)
(a<b) | (a>3)
@
and make sure you understand what happened. 
Use \code{xor} when exclusive OR is needed.
The two forms of AND and OR differ in how they handle vectors. 
The shorter one does element-by-element comparisons; the longer one only looks at the first element in each vector. 

\subsection{More on vector indexing} 

We can also use \emph{logical} vectors (lists of \code{TRUE} and \code{FALSE} values) to pick elements out of vectors.
This is important, e.g., for subsetting data.

As a simple example, we might want to focus on just the low-light values of $r_{\text{max}}$ in the \emph{Chlorella} example:
<<fetch-chlorella-data,echo=F,results='hide'>>=
course.url <- "http://kinglab.eeb.lsa.umich.edu/R_Tutorial/"
X <- read.csv(paste0(course.url,"ChlorellaGrowth.csv"),comment.char='#')
<<>>=
Light <- X[,1]
rmax <- X[,2];
lowLight <- Light[Light<50]
lowLightrmax <- rmax[Light<50]
lowLight
lowLightrmax
@

What is really happening here (think about it for a minute) is that \verb+Light<50+ generates a logical vector the same length as \code{Light} (\code{TRUE TRUE TRUE \ldots}) which is then used to select the appropriate values.

If you want the positions at which \code{Light} is lower than 50, you could say \verb+(1:length(Light))[Light<50]+, but you can also use a built-in function: \verb+which(Light<50)+.  
If you wanted the position at which the maximum value of \code{Light} occurs, you could say \verb+which(Light==max(Light))+.  
(This normally results in a vector of length 1; when could it give a longer vector?)  
There is even a built-in command for this specific function, \code{which.max()} (although \code{which.max()} always returns just the \emph{first} position at which the maximum occurs).

(What would happen if instead of setting \code{lowLight} you replaced \code{Light} by saying \verb+Light <- Light[Light<50]+?
Why would that be the wrong thing to do?)

We can also combine logical operators (making sure to use the element-by-element \verb+&+ and \verb+|+ versions of AND and OR):
<<>>=
Light[Light<50 & rmax <= 2.0]
rmax[Light<50 & rmax <= 2.0]
@

\begin{exercise}
  \code{runif(n)} is a function (more on it soon) that generates a vector of \code{n} random, uniformly distributed numbers between 0 and 1.  
  Create a vector of 20 numbers, then find the subset of those numbers that is less than the mean.
\end{exercise}

\begin{challenge}
  Find the \emph{positions} of the elements that are less than the mean of the vector you just created (e.g. if your vector were \verb+(0.1 0.9 0.7 0.3)+ the answer would be \verb+(1 4)+).
\end{challenge}

As I mentioned in passing above, vectors can have names associated with their elements: if they do, you can also extract elements by name (use \code{names()} to find out the names).

<<>>=
x <- c(first=7,second=5,third=2)
names(x)
x["first"]
x[c("third","first")]
x[c('second','first')] <- c(8,9); x
@

Finally, it is sometimes handy to be able to drop a particular set of elements, rather than taking a particular set: you can do this with negative indices.
For example, \code{x[-1]} extracts all but the first element of a vector.

\begin{challenge}
  Specify two ways to take only the elements in the odd positions (first, third, \ldots) of a vector of arbitrary length.
\end{challenge}

\section{Matrices and arrays}

\subsection{Creating matrices}

A matrix is a two-dimensional array of items.
Most straightforwardly, we can create a matrix by specifying the number of rows and columns, and specifying the entries.
For example 
<<>>=
X <- matrix(c(1,2,3,4,5,6),nrow=2,ncol=3); X
@ 
takes the values 1 to 6 and reshapes them into a 2 by 3 matrix. 
Note that the values in the data vector are put into the matrix \emph{column-wise}, by default.
You can change this by using the optional parameter \code{byrow}: 
<<>>=
A <- matrix(1:9,nrow=3,ncol=3,byrow=TRUE); A
@ 

\R\ will re-cycle through entries in the data vector, if need be, to fill a matrix of the specified size. 
So for example 
<<eval=F>>=
matrix(1,nrow=50,ncol=50)
@ 
creates a $50{\times}50$ matrix, every entry of which is $1$.

\begin{exercise}
  Use a command of the form \code{X~<-~matrix(v,nrow=2,ncol=4)} where \code{v} is a data vector, to create the following matrix \code{X}:
  <<echo=F,comment=''>>=
  print(X <- matrix(rep(c(1,2),times=4),nrow=2))
  @   
\end{exercise}

\R\ will also collapse a matrix to behave like a vector whenever it makes sense: 
for example \code{sum(X)} above is \Sexpr{sum(X)}.


\begin{exercise}
  Use \code{rnorm} and \code{matrix} to create a $5{\times}7$ matrix of Gaussian random numbers with mean 1 and standard deviation 2. 
\end{exercise}
 
Another useful function for creating matrices is \code{diag}.
\code{diag(v,n)} creates an $n{\times}n$ matrix with data vector $v$ on its diagonal. 
So for example \code{diag(1,5)} creates the $5{\times}5$ \emph{identity matrix}, which has 1s on the diagonal and 0 everywhere else.

Finally, one can use the \code{data.entry} function. 
This function can only edit existing matrices, but for example (try this now!)\\
\hspace*{1in} \code{A~<-~matrix(0,3,4); data.entry(A)} \\
will create \code{A} as a $3{\times}4$ matrix, and then call up a spreadsheet-like interface in which the values can be edited directly.

\begin{table}[b]
\begin{tabular}{p{145pt}p{290pt}}
\hline
\code{matrix(v,nrow=m,ncol=n)} & $m \times n$ matrix using the values in \code{v} \\
\code{t(A)} & transpose (exchange rows and columns) of matrix \code{A} \\
\code{dim(X)} & dimensions of matrix X. \code{dim(X)[1]}=\# rows, \code{dim(X)[2]}=\# columns \\
\code{data.entry(A)} & call up a spreadsheet-like interface to edit the values in \code{A} \\
\code{diag(v,n)} & diagonal $n \times n$ matrix with $v$ on diagonal, 0 elsewhere 
(\code{v} is 1 by default, so \code{diag(n)} gives an $n \times n$ identity matrix)\\
\code{cbind(a,b,c,...)} & combine compatible objects by attaching them along columns \\
\code{rbind(a,b,c,...)} & combine compatible objects by attaching them along rows \\
\code{as.matrix(x)} & convert an object of some other type to a matrix, if possible \\
\code{outer(v,w)} & ``outer product'' of vectors \code{v}, \code{w}: the matrix whose 
$(i,j)$\textsuperscript{th}
element is \code{v[i]*w[j]} \\
\hline
\end{tabular}
\caption{Some important functions for creating and working with matrices. 
  Many of these have additional optional arguments; use the help system for full details.}
\label{tab:MatrixFunctions}
\end{table}

\subsection{\code{cbind} and \code{rbind}} 
If their sizes match, vectors can be combined to form matrices, and matrices can be combined with vectors or matrices to form other matrices. 
The functions that do this are \code{cbind} and \code{rbind}. 

\code{cbind} binds together columns of two objects. 
One thing it can do is put vectors together to form a matrix: 
<<>>=
C <- cbind(1:3,4:6,5:7); C
@ 
Remember that \R\ interprets vectors as row or column vectors according to what you're doing with them. 
Here it treats them as column vectors so that columns exist to be bound together. 
On the other hand, 
<<>>=
D <- rbind(1:3,4:6); D
@ 
treats them as rows. 
Now we have two matrices that can be combined. 

\begin{exercise}
  Verify that \code{rbind(C,D)} works, \code{cbind(C,C)} works, but \code{cbind(C,D)} doesn't. 
  Why not? 
\end{exercise}


\subsection{Matrix indexing}
Matrix indexing is like vector indexing except that you have to specify both the row and column, or range of rows and columns. 
For example \code{z~<-~A[2,3]} sets \code{z} equal to 6, which is the (2\textsuperscript{nd} row, 3\textsuperscript{rd} column) entry of the matrix \textbf{A} that you recently created, and 
<<>>=
A[2,2:3]; 
B <- A[2:3,1:2]; B
@ 

There is an easy shortcut to extract entire rows or columns: leave out the limits, leaving a blank before or after the comma.
<<>>=
first.row <- A[1,]; first.row
second.column <- A[,2]; second.column;
@ 

(What does \code{A[,]} do?)

As with vectors, indexing also works in reverse for assigning values to matrix entries. 
For example,
<<>>=
A[1,1] <- 12; A
@ 

The same can be done with blocks, rows, or columns, for example
<<>>=
A[1,] <- c(2,4,5); A
@ 

If you use \code{which()} on a matrix, \R\ will normally treat the matrix as a vector---so for example \code{which(A==8)} will give the answer 6 (figure out why).  
However, \code{which()} does have an option that will treat its argument as a matrix:
<<>>=
which(A>=8,arr.ind=TRUE)
@ 

\subsection{Arrays}

The generalization of the matrix to more (or less) than 2 dimensions is the array.
In fact, in \R, a matrix is nothing other than a 2-dimensional array.
How does \R\ store arrays?
In the simplest possible way: an array is just a vector plus information on the size of the array.
Most straightforwardly, we can create an array from a vector:
<<>>=
X <- array(1:24,dim=c(3,4,2)); X
@ 
Note, again, that the arrays are filled in a particular order: the first dimension first, then the second, and so on.
A one-dimensional array is subtly different from a vector:
<<>>=
y <- 1:5; y
z <- array(1:5,dim=5); z
y==z
identical(y,z)
dim(y); dim(z)
@ 

\begin{exercise}
  What happens when we set the dimension attribute on a vector?
  For example:
<<eval=F>>=
x <- seq(1,27)
dim(x) <- c(3,9)
is.array(x)
is.matrix(x)
@   
\end{exercise}

\section{Factors}

For dealing with measurements on the nominal and ordinal scales \citep{Stevens1946}, \R\ provides vectors of type \emph{factor}.
A factor is a variable that can take one of a finite number of distinct \emph{levels}.
To construct a factor, we can apply the \code{factor} function to a vector of any class:
<<>>=
x <- rep(c(1,2),each=3); factor(x)
trochee <- c("jetpack","ferret","pizza","lawyer")
trochee <- factor(trochee); trochee
@ 
By default, \code{factor} sets the levels to the unique set of values taken by the vector.
To modify that behavior, there is the \code{levels} argument:
<<>>=
factor(trochee,levels=c("ferret","pizza","cowboy","scrapple"))
@ 
Note that the order of the levels is arbitrary, in keeping with the fact that the only operation permissible on the nominal scale is the test for equality.
In particular, the factors created with the \code{factor} command are un-ordered: there is no sense in which we can ask whether, e.g., \verb!ferret < cowboy!.

To represent variables measured on the ordinal scale, \R\ provides \emph{ordered factors}, constructed via the \code{ordered} function.
An ordered factor is just like an un-ordered factor except that the order of the levels matters:
<<echo=F>>=
set.seed(349585885L)
@ 
<<>>=
x <- ordered(sample(x=letters,size=22,replace=TRUE)); x
@ 
Here, we've relied on \code{ordered}'s default behavior, which is to put the levels in alphabetical order.
It's typically safer to specify explicitly what order we want:
<<>>=
x <- ordered(x,levels=rev(letters))
x[1:5] < x[18:22]
@ 

\begin{exercise}
  Look up the documentation on the \code{sample} function used above.
\end{exercise}

\begin{exercise}
  Can I make a matrix or an array out of a factor variable?
\end{exercise}

\begin{challenge}
  What is the internal representation of factors in \R?
  Try converting factors to integers using \code{as.integer}.
  Try converting an integer vector to a factor using \code{factor}.
\end{challenge}

\section{Other structures: Lists and data frames}

\subsection{Lists}
While vectors and matrices may seem familiar, lists may be new to you.
Vectors and matrices have to contain elements that are all the same type: 
lists in \R\ can contain anything---vectors, matrices, other lists, \ldots.
Indexing is a little different too: use \code{[[ ]]} to extract an element of a list by number or name or \verb+$+ to extract an element by name (only).
Given a list like this:
<<>>=
L <- list(A=x,B=trochee,C=c("a","b","c"))
@ 
Then \verb+L$A+, \verb+L[["A"]]+, and \verb+L[[1]]+ will each return the first element of the list.
To extract a sublist, use the ordinary single square brackets: \verb+[]+:
<<>>=
L[c("B","C")]
@ 


\subsection{Data frames}

Vectors, matrices, and lists of one sort or another are found in just about every programming language.
The \emph{data frame} structure is (or was last time I checked) unique to \R, and is central to many of \R's useful data-analysis features.
It's very natural to want to store data in vectors and matrices.
Thus, in the example above, we stored measurements of two variables ($r_\text{max}$ and light level) in vectors.
This was done in such a way that the observations of the first replicate were stored in the first element of each vector, the second in the second, and so on.
To explicitly bind together observations corresponding to the same replicate, we might join the two vectors into a matrix using \code{cbind}.
In the resulting data structure, each row would correspond to an observation, each column to a variable.
This is possible, however, only because both variables are of the same type: they're both numerical.
More commonly, a data set is made up of several different kinds of variables.
The data frame is \R's solution to this problem.

Data frames are a hybrid of lists and vectors.
Internally, they are a list of vectors which can be of different types but must all be the same length.
However, they behave somewhat like matrices, in that you can do most things to them that you can do with matrices.
You can index them either the way you would index a list, using \verb+[[ ]]+ or \verb+$+---where each variable is a different item in the list---or the way you would index a matrix.  
You can turn a data frame into a matrix (using \code{as.matrix()}, but only if all variables are of the same class) and a matrix into a data frame (using \code{as.data.frame()}).

When data are read into \R\ from an external file using one of the \code{read.xxx} commands (\code{read.csv}, \code{read.table}, \code{read.xls}, etc.), the object that is created is a data frame.
<<>>=
course.url <- "http://kinglab.eeb.lsa.umich.edu/R_Tutorial/"
dat <- read.csv(file.path(course.url,"ChlorellaGrowth.csv"),
                comment.char='#')
dat
@ 

\begin{exercise}
  Download the \code{hurricanes.csv} file from the above course URL.
  Examine the resulting data frame by printing it and using the \code{str} command.
  Note the class type of each variable.
\end{exercise}

\section{Probability distributions in R}

\pkg{R} contains a great deal of distilled knowledge about probability distributions.
In particular, for each of a large class of important distributions, methods to compute probability distribution functions (p.d.f., i.e., density or mass functions), cumulative distribution functions (c.d.f.), and quantile functions are available, as are methods for simulating these distributions (i.e., drawing random deviates with the desired distribution).
Conveniently, these are all named using the same scheme:
\begin{center}
  \begin{tabular}{l l}
    \hline\hline
    \verb+dxxx(x, ...)+ & probability distribution function\\
    \verb+pxxx(q, ...)+ & cumulative distribution function\\
    \verb+qxxx(p, ...)+ & quantile function (i.e., inverse of \code{pxxx})\\
    \verb+rxxx(n, ...)+ & simulator\\
    \hline\hline
  \end{tabular}
\end{center}

In the above \code{xxx} stands for the abbreviated name of the specific distribution (the ``\R\ name'' as given in \cref{tab:distribs}).
In each case, the \code{...} indicates that additional, distribution-specific, parameters are to be supplied.
\Cref{tab:distribs} lists some of the more common distributions built in to \R.
A complete list of distributions provided by the base \pkg{stats} package can be viewed by executing \verb+?Distributions+.

\begin{table}[h!]
  \caption{Some of the probability distributions built in to \R.
    For complete documentation, execute e.g., \code{?dbinom} in an \R\ session.
    \label{tab:distribs}}
  \begin{tabular}{| l l l l |}
    \hline\hline
    Distribution & \R\ name & Parameters & Range\\
    \hline
    \multicolumn{4}{| l |}{Discrete distributions}\\
    \hline
    Binomial & \code{binom} & size, prob & $0,1,\dots,\mathrm{size}$\\
    Bernoulli & \code{binom} (\code{size=1}) & prob & $0,1$\\
    Poisson & \code{pois} & lambda & $0,1,\dots,\infty$\\
    Negative binomial & \code{nbinom} & size, (prob or mu) & $0,1,\dots,\infty$\\
    Geometric & \code{geom} & rate & $0,1,\dots,\infty$\\
    Hypergeometric & \code{hyper} & m, n, k & $0,1,\dots,m$\\
    Multinomial & \code{multinom} & size, $\mathrm{prob}\in[0,1]^m$ & $\{(x_1,\dots,x_m): \sum\!x_i=\mathrm{size}\}$\\
    \hline
    \multicolumn{4}{| l |}{Continuous distributions}\\
    \hline
    Uniform & \code{unif} & min, max & $[\mathrm{min},\mathrm{max}]$\\
    Normal & \code{norm} & mean, sd & $(-\infty,\infty)$\\
    Gamma & \code{gamma} & shape, (scale or rate) & $[0,\infty)$\\
    Exponential & \code{exp} & mu & $[0,\infty)$\\
    Beta & \code{beta} & shape1, shape2 & $[0,1]$\\
    Lognormal & \code{lnorm} & meanlog, sdlog & $[0,\infty)$\\
    Cauchy & \code{cauchy} & location, scale & $(\infty,\infty)$\\
    $\chi^2$ & \code{chisq} & df & $[0,\infty)$\\
    Student's T & \code{t} & df & $[0,\infty)$\\
    Weibull & \code{weibull} & shape, scale & $[0,\infty)$\\
    \hline\hline
  \end{tabular}
\end{table}

\begin{exercise}
  Write codes to plot the c.d.f.\ of the binomial distribution (\code{pbinom}).
  Verify the relationship between the p.d.f.\ (\code{dbinom}) and the c.d.f.
\end{exercise}

\begin{exercise}
  Plot the p.d.f.\ and c.d.f.\ of the Poisson distribution for several values of the parameter $\lambda$.
\end{exercise}

\begin{exercise}
  Plot the p.d.f.\ and c.d.f.\ of the gamma distribution for several values of the shape and scale (or rate) parameters.
  Put in a vertical line to indicate the mean.
  Be sure to explore both large and small values of the shape parameter.
\end{exercise}

\begin{exercise}
  Use \pkg{Rstudio}'s \code{manipulate} facility to plot the p.d.f.\ and c.d.f.\ of the beta distribution for several values of the first and second shape parameters.
  Put in a vertical line to indicate the mean.
  Be sure to explore the full ranges of the parameters.
\end{exercise}

\section{Script files and data files}

Modeling and complicated data analysis are often accomplished more efficiently using \emph{scripts}, which are a series of  commands stored in a text file. 
The Windows and MacOS versions of \R\ both have basic script editors.
You can also use Windows Notepad or Wordpad, or a more featureful editor like PFE, emacs (with ESS, ``emacs speaks statistics''), or Tinn-R: 
you \textbf{should not} use MS Word or other fancy editors (see below).

Most programs for working with models or analyzing data follow a simple pattern of program parts:
\begin{enumerate}
\item Setup statements.
\item Input some data from a file.
\item Carry out the calculations that you want.
\item Print the results, graph them, and/or save them to a file.
\end{enumerate}

For example, a script file might
\begin{enumerate}
\item Load some packages, or ``source'' another script file that creates some functions (more on functions later). 
\item Read in data from a text file.
\item Fit several statistical models to the data and compare them.
\item Graph the results, and save the graph to disk for including in your paper. 
\end{enumerate}
Even for relatively simple tasks, script files are useful for building up a calculation step-by-step, making sure that each part works before adding on to it.
They are also \textbf{essential} for making research reproducible.

Tips for working with data and script files (sounding slightly scary but just trying to help you avoid common pitfalls):
\begin{itemize}

\item To let \R\ know where data and script files are located, you have a few choices:
  \begin{enumerate}
  \item change your working directory to wherever the file(s) are located before running \R.
  \item change your working directory within an \R\ session to wherever the file(s) are located using the \code{setwd()} (\textbf{set} \textbf{w}orking \textbf{d}irectory) function, e.g. \verb+setwd("c:/temp")+.
  \item spell out the path to the file explicitly. 
    Use a single forward slash to separate folders (e.g., \windows\ \verb+"c:/My~Documents/R/script.R"+ or \nix\ \verb+"/home/kingaa/projects/hurricanes"+): this works on all platforms.
  \end{enumerate}
  The first option is far preferable, since it makes your codes portable:
  as long as you copy the whole directory, you can copy it whereever you like and \R\ will find what it needs.

\windows 
If you have a shortcut defined for \R\ on your desktop (or possibly in the Start menu) you can \emph{permanently} change your default working directory by right-clicking on the shortcut icon, selecting \code{Properties}, and changing the starting directory to somewhere like (for example) \code{My~Documents/projectX}.

\item It's important that script files be preserved as \emph{plain text} and data files also as plain text, using comma- or tab-separated format.
  There are three things that can go wrong here: 
  \begin{enumerate}[(1)]
  \item if you use a web browser to download files, be careful that it doesn't automatically append some weird suffix to the files or translate them into something other than plain text.
  \item if your web browser uses ``file associations'' (e.g., it thinks that all files ending in \code{.dat} are Excel files), make sure to save the file as plain text, and without any extra extensions; 
  \item \textbf{never use Microsoft Word to edit your data and script files}; MS Word will try very hard to get you to save them as Word (rather than text) files, which will screw them up!
  \end{enumerate}

\item If you send script files by e-mail, even if you are careful to send them as plain text, lines will occasionally get broken in different places, which can lead to confusion.  
  Beware.
\end{itemize}

As a first example, the file \code{Intro1.R} has the commands from the interactive regression analysis. 
%% \textbf{Important:} before working with an example file, create a personal copy in some location on your own computer. 
%% We will refer to this location as your \emph{temp folder}. 
%% At the end of a lab session you \textbf{must} move files onto your personal disk (or email them to yourself).  

Download \code{Intro1.R} and save it to your computer:
<<>>=
download.file(paste0(course.url,"Intro1.R"),destfile="Intro1.R",mode="w")
@ 
Open \textbf{your copy} of \code{Intro1.R}. 
In your editor, select and Copy the entire text of the file, and then Paste the text into the \R\ console window. 
This has the same effect as entering the commands by hand into the console: they will be executed and so a graph is displayed with the results. 
Cut-and-Paste allows you to execute script files one piece at a time (which is useful for finding and fixing errors). 
The \code{source} function allows you to run an entire script file, e.g., 
<<eval=FALSE>>=
source("Intro1.R")
@

Another important time-saver is loading data from a text file. 
Grab copies of \code{Intro2.R} and \code{ChlorellaGrowth.csv} from the dropsite to see how this is done. 
<<>>=
download.file(paste0(course.url,"Intro2.R"),destfile="Intro2.R",mode="w")
download.file(paste0(course.url,"ChlorellaGrowth.csv"),destfile="ChlorellaGrowth.csv",mode="w")
@ 
In \code{ChlorellaGrowth.csv} the two variables are entered as columns of a data matrix. 
Then instead of typing these in by hand, the command
<<echo=F,results='hide'>>=
<<fetch-chlorella-data>>  
<<eval=F>>=
X <- read.csv("ChlorellaGrowth.csv",comment.char='#')
@
reads the file (from the current directory) and puts the data values into the variable \code{X}.
\textbf{Note} that as specified above you need to make sure that \R\ is looking for the data file in the right place:
either move the data file to your current working directory, or change the line so that it points to the actual location of the data file.
Note also the \code{comment.char} option in the call to \code{read.csv}; 
this tells \R\ to ignore lines that begin with a \verb+#+ and allows us to use self-documenting data files (a very good practice).

Extract the variables from \code{X} with the commands
<<>>=
Light <- X[,1]
rmax <- X[,2]
@ 
Think of these as shorthand for ``\code{Light} = everything in column 1 of \code{X}'', and ``\code{rmax} = everything in column 2 of \code{X}'' (we'll learn about working with data matrices later). From there on out it's the same as before, with some additions
that set the axis labels and add a title.  

\begin{exercise}
  Make a copy of \code{Intro2.R} under a new name, and modify the copy so that it does linear regression of algal growth rate on the natural log of light intensity, \code{LogLight=log(Light)}, and plots the data appropriately. 
  You should end up with a graph that resembles \Cref{fig:Intro1Fig2}. 
\end{exercise}

\begin{figure}
<<echo=FALSE,results='hide',fig.width=8,fig.height=6>>=
Light <- X$light; rmax <- X$rmax
logLight <- log(Light)
op <- par(cex=1.5,cex.main=0.9)
plot(logLight,rmax,xlab="Log light intensity (uE/m2/s)", ylab="Maximum growth rate rmax (1/d)",pch=16); 
title(main="Data from Fussmann et al. (2000) system");
fit <- lm(rmax~logLight);
summary(fit); abline(fit); 
rcoef <- round(coef(fit),digits=3)
text(3.7,3.5,paste("rmax=",rcoef[1],"+",rcoef[2],"log(Light)"));
par(op)
@ 
\caption{Graphical summary of regression analysis using log of light intensity (with plot annotations).}
\label{fig:Intro1Fig2}
\end{figure}

\begin{exercise}
  Run \code{Intro2.R}, then enter the command \code{plot(fit)} in the console and follow the directions in the console.
  Figure out what just happened by entering \code{?plot.lm} to bring up the help page for the function \code{plot.lm()} that carries out a \code{plot()} command for an object produced by \code{lm()}. 
  (This is one example of how \R\ uses the fact that statistical analyses are stored as model objects. 
  \code{fit} ``knows'' what kind of object it is (in this case an object of type \code{lm}), and so \code{plot(fit)} invokes a function that produces plots suitable for an \code{lm} object.) 
  \textbf{Answer:} \R\ produced a series of diagnostic plots exploring whether or not the fitted linear model is a suitable fit to the data. In each of the plots, the 3 most extreme points (the most likely candidates for ``outliers'') have been identified according to their sequence in the data set. 
\end{exercise}

  The axes in plots are scaled automatically, but the outcome is not always ideal (e.g. if you want several graphs with exactly the same axes limits). 
  You can control scaling using the \code{xlim} and \code{ylim} arguments in \code{plot}:\\
  \hspace*{1in}  \code{plot(x,y,xlim=c(x1,x2), [other stuff]) } \\
  will draw the graph with the $x$-axis running from \code{x1} to \code{x2}, and using \code{ylim=c(y1,y2)} within the \code{plot()} command will do the same for the $y$-axis. 

\begin{exercise}
  Create a plot of growth rate versus light intensity with the $x$-axis running from 0 to 120, and the $y$-axis running from 1 to 4. 
\end{exercise}

\begin{exercise}
  Several graphs can be placed within a single figure by using the \code{par} function (short for ``parameter'') to adjust the layout of the plot. 
  For example the command \\
  \hspace*{0.5in} \code{par(mfrow=c(m,n))} \\
  divides the plotting area into $m$ rows and $n$ columns. 
  As a series of graphs is drawn, they are placed along the top row from left to right, then along the next row, and so on.
  \code{mfcol=c(m,n)} has the same effect except that successive graphs are drawn down the first column, then down the second column, and so on. 

  Save \code{Intro2.R} with a new name and modify the program as follows. 
  Use \code{mfcol=c(2,1)} to create graphs of growth rate as a function of \code{Light}, and of \code{log(growth rate)} as a function of \code{log(Light)} in the same figure.  
  Do the same again, using \code{mfcol=c(1,2)}. 
\end{exercise}

\begin{challenge}
  Use \code{?par} to read about other plot control parameters that can be set using \code{par()}.
  Then draw a $2 \times 2$ set of plots, each showing the line $y=5x+3$ with x running from 3 to 8, but with 4 different line styles and 4 different line colors. 
\end{challenge}

\begin{challenge}
  Modify one of your scripts so that at the very end it saves the plot to disk. 
  You can accomplish this using the \code{dev.print()} function.
  Do \code{?dev.print} to read about this function. 
  Note that you need to specify the \code{file} argument to write your graphics to a file; if you don't, it will try and send it to a printer.
  Also note that many alternative formats are available via the \code{dev} argument.
\end{challenge}

\section{Looping in \R}

Very frequently, a computation involves iterating some procedure across a range of cases, and every computer language I've ever come across has one or more facilities for producing such \emph{loops}.
\R\ is no exception, though judging by their code, many \R\ programmers look down their noses at loops.
The fact remains that, at some point in life, one simply has to write a \code{for} loop.
Here, we'll look at the looping constructs available in \R.

\subsection{\code{for} loops}

Execute the following code.
<<results='hide'>>=
phi <- 1
for (k in 1:1000) {
  phi <- 1+1/phi
  print(c(k,phi))
}
@ 
What does it do?
Sequentially, for each value of \code{k} between 1 and 1000, \code{phi} is modified.
More specifically, at the beginning of the \code{for} loop, a vector containing all the integers from 1 to 1000 in order is created.
Then, \code{k} is set to the first element in that vector, i.e., 1.
Then the \R\ expression from the \verb+{+ to the \verb+}+ is evaluated.
When that expression has been evaluated, \code{k} is set to the next value in the vector.
The process is repeated until, at the last evaluation, \code{k} has value 1000.

As an aside, note that the final value of \code{phi} is the Golden Ratio, \Sexpr{signif((sqrt(5)+1)/2,12)}.
\Sexpr{if (phi!=(sqrt(5)+1)/2) "LIE!!"}

As an example of a situation where a loop of some sort is really needed, suppose we wish to iterate the Beverton-Holt map (one of the simplest discrete-time models of population growth),
\begin{equation*}
  N_{t+1} = \frac{a\,N_t}{1+b\,N_t}.
\end{equation*}
We simply have no option but to do the calculation one step at a time.
Here's an \R\ code that does this
<<>>=
a <- 1.1
b <- 0.001
T <- seq(from=1,to=200,by=1)
N <- numeric(length(T))
n <- 2
for (t in T) {
  n <- a*n/(1+b*n)
  N[t] <- n
}
@ 
Spend some time to make sure you understand what happens at each line of the above.
We can plot the population sizes $N_t$ through time via
<<>>=
plot(T,N)
@ 

\paragraph{Gotcha:}
An alternative way to do the above might be something like
<<>>=
N <- numeric(length(T))
for (t in 1:length(T)) {
  n <- a*n/(1+b*n)
  N[t] <- n
}
@ 

\begin{exercise}
  Check that this works with different vectors \code{T}.
  What happens when \code{T} has length 1?
  What happens when \code{T} has length 0?  Why?
  To avoid this trap, it's preferable to use \code{seq\_len}, \code{seq\_along}, or \code{seq.int} instead of the \verb+1:n+ construction used above.
  This and many other \R\ gotchas are described in the useful \emph{R Inferno} \citep{Burns2012}, a free version of which can be downloaded from the course readings site.
\end{exercise}


\subsection{\code{while} loops}

A second looping construct is the \code{while} loop.
Using \code{while}, we can compute the Golden Ratio as before:
<<results='hide'>>=
phi <- 20
k <- 1
while (k <= 1000) {
  phi <- 1+1/phi
  print(c(k,phi))
  k <- k+1
}
@ 
What's going on here?
First, \code{phi} and \code{k} are initialized.
Then the \code{while} loop is started.
At each iteration of the loop, \code{phi} is modified, and intermediate results printed, as before.
In addition, \code{k} is incremented.
The \code{while} loop continues to iterate until the condition \verb+k <= 1000+ is no longer \code{TRUE}, at which point, the \code{while} loop terminates.

Note that here we've chosen a large number (1000) of iterations.
Perhaps we could get by with fewer.
If we wanted to terminate the iterations as soon as the value of \code{phi} stopped changing, we could do:
<<results='hide'>>=
phi <- 20
conv <- FALSE
while (!conv) {
  phi.new <- 1+1/phi
  conv <- phi==phi.new
  phi <- phi.new
}
@ 

\begin{exercise}
  Verify that the above works as intended.
  How many iterations are needed?
\end{exercise}

Another way to accomplish this would be to use \code{break} to stop the iteration when a condition is met.
For example
<<results='hide'>>=
phi <- 20
while (TRUE) {
  phi.new <- 1+1/phi
  if (phi==phi.new) break
  phi <- phi.new
}
@ 
While this \code{while} loop is equivalent to the one before, it does have the drawback that, if the \code{break} condition is never met, the loop will go on indefinitely.
An alternative that avoids this is to use a \code{for} loop with a large (but necessarily finite) number of iterations, together with \code{break}:
<<results='hide'>>=
phi <- 3
for (k in seq_len(1000)) {
  phi.new <- 1+1/phi
  if (phi==phi.new) break
  phi <- phi.new
}
@ 

\begin{exercise}
  Recompute the trajectory of the Beverton-Holt model using a \code{while} loop.
  Verify that your answer is exactly equivalent to the one above.
\end{exercise}

\subsection{\code{repeat} loops}

A third looping construct in \R\ involves the \code{repeat} keyword.
For example,
<<>>=
phi <- 12
repeat {
  phi.new <- 1/(1+phi)
  if (phi==phi.new) break
  phi <- phi.new
}
@ 

In addition, \R\ provides the \code{next} keyword, which, like \code{break}, is used in the body of a looping construct.
Rather than terminating the iteration, however, it aborts the current iteration and leads to the immediate execution of the next iteration.

For more information on looping and other control-flow constructs, execute \verb+?Control+.

\section{Functions and environments}

\subsection{Definitions and examples}

An extremely useful feature in \R\ is the ability to write arbitrary \emph{functions}.
A function, in this context, is an algorithm that performs a specific computation that depends on inputs (the function's \emph{arguments}) and produces some output (the function's \emph{value}) and/or has some \emph{side effects}.
Let's see how this is done.

Here is a function that squares a number.
<<>>=
sq <- function (x) x^2
@ 
The syntax is \verb+function (arglist) expr+.
The one argument in this case is \code{x}.
When a particular value of \code{x} is supplied, \R\ performs the squaring operation.
The function then \emph{returns} the value \verb!x^2!:
<<>>=
sq(3); sq(9); sq(-2);
@ 

Here is a function with two arguments and a more complex \emph{body}, as we call the expression that is evaluated when the function is called.
<<>>=
f <- function (x, y = 3) {
  a <- sq(x)
  a+y
}
@
Here, the body is the \R\ expression from \verb+{+ to \verb+}+. 
Unless the \code{return} codeword is used elsewhere in the function body, the value returned is always the last expression evaluated.
Thus:
<<>>=
f(3,0); f(2,2); f(3);
@ 
Note that in the last case, only one argument was supplied.
In this case, \code{y} assumed its default value, 3.

Note that functions need not be assigned to symbols; they can be \emph{anonymous}:
<<>>=
function (x) x^5
(function (x) x^5)(2)
@ 

A function can also have side effects, e.g.,
<<>>=
hat <- "hat"
hattrick <- function (y) {
  hat <<- "rabbit"
  2*y
}
hat; hattrick(5); hat
@ 
However, the very idea of a function insists that we should never experience \emph{unintentional} side effects.
We'll see how \R\ realizes this imperative below.

\paragraph{An aside} 
If we want the function not to automatically print, we can wrap the return value in \code{invisible()}:
<<>>=
hattrick <- function (y) {
  hat <<- "rabbit"
  invisible(2*y)
}
hattrick(5)
print(hattrick(5))
@ 

A function in \R\ is defined by three components:
\begin{inparaenum}[(1)]
  \item its \emph{formal parameters}, i.e., its argument list,
  \item its body, and
  \item its \emph{environment}, i.e., the context in which the function was defined.
\end{inparaenum}
\R\ provides simple functions to interrogate these function components:
<<>>=
formals(hattrick)
body(hattrick)
environment(hattrick)
@ 

\subsection{Function scope}

\footnote{This section draws heavily, and sometimes verbatim, on {\S}10.7 of the \emph{Introduction to \R} manual \citep{RIntro}.}As noted above, a paramount consideration in the implementation of functions in any programming language is that unintentional side effects should never occur.
In particular, I should be free to write a function that creates temporary variables as an aid to its computations, and be able to rest assured that no variables I create temporarily will interfere with any other variables I've defined anywhere else.
To accomplish this, \R\ has a specific set of \emph{scoping rules}.

Consider the function
<<>>=
f <- function (x) {
  y <- 2*x
  print(x)
  print(y)
  print(z)
}
@ 
In this function's body, \code{x} is a formal parameter, \code{y} is a local variable, and \code{z} is a free, or \emph{unbound} variable.
When \code{f} is evaluated, each of these variables must be \emph{bound} to some value.
In \R, the free variable bindings are resolved---each time the function is evaluated---by first looking in the environment where the function was created.
This is called \emph{lexical scope}.
Thus if we execute
<<echo=F,results='hide'>>=
rm(z)
<<eval=F>>=
f(3)
@ 
we get an error, because no object named \code{z} can be found.
If, however, we do
<<>>=
z <- 10
f(3)
@ 
we don't get an error, because \code{z} is defined in the environment, \verb+<environment: R_GlobalEnv>+, of \code{f}.
Similarly, when we do
<<>>=
z <- 13
g <- function (x) {
  2*x+z
}
f <- function (x) {
  z <- -100
  g(x)
}
f(5)  
@ 
The relevant value of \code{z} is the one in the environment where \code{g} was \emph{defined}, not the one in the environment wherein it is \emph{called}.

\subsection{Nested functions and environments}

In each of the following examples, make sure you understand exactly what has happened.

Consider this:
<<>>=
y <- 11
f <- function (x) {
  y <- 2*x
  y+x
}
f(1); y
@ 

\begin{exercise}
  Why hasn't \code{y} changed its value?
\end{exercise}

What about this?
<<>>=
y <- 0
f <- function (x) {
  2*x+y
}
f(1); y
@ 

\begin{exercise}
  Why is the return value of \code{f} different?
\end{exercise}

How about the following?
<<>>=
g <- function (y) y
f <- function (x) {
  g <- function (y) {
    2*y
  }
  11+g(x)
}
f(2); g(2)
@ 

\begin{exercise}
  Be sure you understand what's happening at each line and why you get the results you see.
\end{exercise}

Another example:
<<>>=
y <- 11
f <- function (x) {
  y <- 22
  g <- function (x) {
    x+y
  }
  g(x)
}
f(1); y
@ 

\begin{exercise}
  Which value of \code{y} was used?
\end{exercise}

Compare that with this:
<<>>=
y <- 11
f <- function (x) {
  y <- 22
  g <- function (x) {
    y <<- 7
    x+y
  }
  c(g(x),y)
}
f(1); y
@ 
and this:
<<>>=
y <- 11
f <- function (x) {
  g <- function (x) {
     x+y
  }
  g(x)
}
f(1); y
@ 
and this:
<<>>=
f <- function (x) {
  y <- 37
  g <- function (x) {
    h <- function (x) {
      x+y
    }
    h(x)
  }
  g(x)
}
f(1); y
@ 
Finally, consider the following:
<<>>=
rm(y)
f <- function (x) {
   g <- function (x) {
     y <<- 2*x
     y+1
   }
   g(x)+1
 }
f(11); y
f(-2); y
@ 

\begin{exercise}
  In the above five code snippets, make sure you understand the differences.
\end{exercise}

As mentioned above, each function is associated with an environment: the environment within which it was defined.
When a function is evaluated, a new temporary environment is created, within which the function's calculations are performed.
Every new environment has a parent, the environment wherein it was created.
The parent of this new environment is the function's environment.
To see this, try
<<results='markup'>>=
f <- function () {
  g <- function () {
    h <- function () {
      cat("inside function h:\n")
      cat("current env: ")
      print(sys.frame(sys.nframe()))
      cat("parent env: ")
      print(parent.frame(1))
      cat("grandparent env: ")
      print(parent.frame(2))
      cat("great-grandparent env: ")
      print(parent.frame(3))
      invisible(NULL)
    }
    cat("inside function g:\n")
    cat("environment of h: ")
    print(environment(h))
    cat("current env: ")
    print(sys.frame(sys.nframe()))
    cat("parent env: ")
    print(parent.frame(1))
    cat("grandparent env: ")
    print(parent.frame(2))
    h()
  }
  cat("inside function f:\n")
  cat("environment of g: ")
  print(environment(g))
  cat("current env: ")
  print(sys.frame(sys.nframe()))
  cat("parent env: ")
  print(parent.frame(1))
  g()
}
cat("environment of f: "); print(environment(f))
cat("global env: "); print(sys.frame(sys.nframe()))
f()
@ 

Each variable referenced in the function's body is bound, first, to a formal argument if possible.
If a local variable of that name has previously been created (via one of the assignment operators \verb+<-+, \verb+->+, or \verb+=+, this is the variable that is affected by any subsequent assignments.
If the variable is neither a formal parameter nor a local variable, then the parent environment of the function is searched for that variable.
If the variable has not been found in the parent environment, then the grand-parent environment is searched, and so on.

If the assignment operators \verb+<<-+ or \verb+->>+ are used, a more extensive search for the referenced assignee is made.
If the variable does not exist in the local environment, the parent environment is searched.
If it does not exist in the parent environment, then the grand-parent environment is searched, and so on.
Finally, if the variable cannot be found anywhere along the lineage of environments, a new global variable is created, with the assigned value.

\section{The \code{apply} family of functions}

As mentioned above, there are circumstances under which looping constructs are really necessary.
Very often, however, we wish to perform some operation across all the elements of a vector, array, or dataset.
In such cases, it is faster and more elegant (to the \R\ afficiando's eye) to use the \code{apply} family of functions.

\subsection{List apply: \code{lapply}}

\code{lapply} applies a function to each element of a list or vector, returning a list.
<<>>=
  x <- list("teenage","mutant","ninja","turtle",
            "hamster","plumber","pickle","baby")
  lapply(x,nchar)

  y <- c("teenage","mutant","ninja","turtle",
         "hamster","plumber","pickle","baby")
  lapply(y,nchar)
@ 

\subsection{Sloppy list apply: \code{sapply}}

\code{sapply} isn't content to always return a list:
it attempts to simplify the results into a non-list vector if possible.
<<>>=
  x <- list("teenage","mutant","ninja","turtle",
            "hamster","plumber","pickle","baby")
  sapply(x,nchar)

  y <- c("teenage","mutant","ninja","turtle",
         "hamster","plumber","pickle","baby")
  sapply(y,nchar)
@ 

\subsection{Multiple-list apply: \code{mapply}}

\code{mapply} is a multiple-argument version of \code{sapply}:
<<>>=
  x <- c("teenage","mutant","ninja","turtle")
  y <- c("hamster","plumber","pickle","baby")
  mapply(paste,x,y,sep="/")
@ 
As usual, the recycling rule applies:
<<>>=
  mapply(paste,x,y[2:3])
  mapply(paste,x[c(1,3)],y)
@ 

\subsection{Array apply: \code{apply}}

\code{apply} is very powerful and a bit more complex.
It allows an arbitrary function to applied to each slice of an array, where the slices can be defined in all possible ways.
Let's create a matrix:
<<>>=
  A <- array(data=seq_len(15),dim=c(3,5)); A
@ 
To apply an operation to each row, we \emph{marginalize} over the first dimension (rows).
For example, to sum the rows, we'd do
<<>>=
  apply(A,1,sum)
@ 
To sum the columns (the second dimension), we'd do
<<>>=
  apply(A,2,sum)
@ 

Now suppose we have a 3-dimensional array:
<<>>=
  A <- array(data=seq_len(30),dim=c(3,5,2)); A
@ 
To sum the rows within each slice, we'd do
<<>>=
  apply(A,c(1,3),sum)
@ 
while to sum the slices, we'd do
<<>>=
  apply(A,3,sum)
@ 
For each of the above, make sure you understand exactly what has happened.

Of course, we can apply an anonymous function wherever we apply a named function:
<<>>=
  apply(A,c(2,3),function (x) sd(x)/sqrt(length(x)))
@ 
Additional arguments are passed to the function:
<<>>=
  apply(A,c(1,2),function (x, y) sum(x>y),y=8)
  apply(A,c(1,2),function (x, y) sum(x>y),y=-1)
@ 

\subsection{Table apply: \code{tapply}}

\code{tapply} is, in a way, an extension of \code{table}.
The syntax is \verb!tapply(X,INDEX,FUN,...)!,
where \code{X} is a vector, \code{INDEX} is a list of one or more factors, each the same length as \code{X}, and \code{FUN} is a function.
The vector \code{X} will be split into subvectors according to \code{INDEX}, and \code{FUN} will be applied to each of the subvectors.
By default, the result is simplified into an array if possible.
Some examples:
<<>>=
  x <- seq(1,30,by=1)
  b <- rep(letters[1:10],times=3)
  data.frame(x,b)
  tapply(x,b,sum)

  b <- rep(letters[1:10],each=3)
  data.frame(x,b)
  tapply(x,b,sum)
@ 

<<>>=
  course.url <- "http://kinglab.eeb.lsa.umich.edu/R_Tutorial/"
  datafile <- "seedpred.dat"
  seeds <- read.table(paste0(course.url,datafile),header=TRUE,
                      colClasses=c(station='factor',dist='factor',date='Date'))
  x <- subset(seeds,available>0)
  with(x, tapply(tcum,list(dist,station),max,na.rm=TRUE))

@ 

\subsection{sapply with expected result: \code{vapply}}

When we could use \code{sapply} and we know exactly what the size and class of the value of the function will be, it is sometimes faster to use \code{vapply}.
The syntax is like that of \code{sapply}: \verb+vapply(X,FUN,FUN.VALUE,...)+, where \code{X} and \code{FUN} are as in \code{sapply}, but we specify the size and class of the value of \code{FUN} via the \code{FUN.VALUE} argument.
For example, suppose we define a function that, given a number between 1 and 26 will return the corresponding letter of the alphabet:
<<>>=
alph <- function (x) {
  if (x < 1 || x > 26) stop("bad value of x")
  LETTERS[as.integer(x)]
}
@ 
This function will return a vector of length 1 and class \code{character}.
To apply it to a randomly sampled set of integers, we might do
<<echo=F,results='hide'>>=
  set.seed(1950064303L)
<<>>=
  x <- sample(1:26,50,replace=TRUE)
  y <- vapply(x,alph,character(1))
  paste(y,collapse="")
@ 

%% Bank-account example?


\section{Vectorized functions vs.~loops}

As \citet{Ligges2008} point out, the idea that one should avoid loops wherever possible in \R, using instead vectorized functions like those in the \code{apply} family, is quite widespread in some quarters.
The belief, which probably dates back to infelicities in early versions of \pkg{S} and \pkg{Splus} but is remarkably persistent, is that loops are very slow in \R.
Let's have a critical look at this.

Consider the following loop code that can be vectorized:
<<>>=
x <- runif(n=1e6,min=0,max=2*pi)
y <- numeric(length(x))
for (k in seq_along(x)) {
  y[k] <- sin(x[k])
}
@ 
To time this, we can wrap the vectorizable parts in a call to \code{system.time}:
<<cache=F>>=
x <- runif(n=1e6,min=0,max=2*pi)
system.time({
  y <- numeric(length(x))
  for (k in seq_along(x)) {
    y[k] <- sin(x[k])
  }
})
@ 
We can compare this with a simple call to \code{sin} (which is vectorized):
<<cache=F>>=
system.time(z <- sin(x))
@ 
Clearly, calling \code{sin} directly is much faster.
What about using \code{sapply}?

\begin{exercise}
  Compare the time spent on the equivalent calculation, using \code{sapply}.
  What does this result tell you about where the computational cost is incurred?
<<echo=F,cache=F>>=
system.time(w <- sapply(x,sin))
@ 
\end{exercise}

The above example is very simple in that there is a builtin function (\code{sin} in this case) which is capable of the fully vectorized computation.
In such a case, it is clearly preferable to use it.
Frequently, however, no such builtin function exists, i.e., we have a custom function of our own we want to apply to a set of data.
Let's compare the relative speeds of loops and \code{sapply} in this case.
<<cache=F>>=
x <- seq.int(from=20,to=1e6,by=10)
f <- function (x) {
  (((x+1)*x+1)*x+1)*x+1
}
system.time({
  res1 <- numeric(length(x))
  for (k in seq_along(x)) {
    res1[k] <- f(x[k])
  }
})
system.time(res2 <- sapply(x,f))
@
[Actually, in this case, \code{f} is vectorized automatically.
Why is this?]
<<cache=F>>=
system.time(f(x))
@ 

Another example: in this case function \code{g} is not vectorized.
<<cache=F>>=
g <- function (x) {
  if ((x[1] > 30) && (x[1] < 5000)) {
    1
  } else {
    0
  }
}

system.time({
  res1 <- numeric(length(x))
  for (k in seq_along(x)) {
    res1[k] <- g(x[k])
  }
})
system.time(res2 <- sapply(x,g))
@ 

\section*{Acknowledgments}

These notes are based in part on materials used in the series of NSF-funded workshops taught in association with the Ecology and Evolution of Infectious Diseases conference.
Instructors there included Ben Bolker, Ottar Bj{\o}rnstad, Steve Ellner, and Stu Field.
Steve Ellner contributed the document that formed the early skeleton of these notes; he based them in turn on course materials by Colleen Webb, Jonathan Rowell, and Daniel Fink at Cornell, Professors Lou Gross (University of Tennessee) and Paul Fackler (NC State University), and on the book \emph{Getting Started with Matlab} by Rudra Pratap (Oxford University Press).  
The document also draws on the documentation supplied with \R, including the \emph{Introduction to \R} manual.
Versions of this document have been used in courses taught by BB and AAK at Florida and Michigan, at workshops run under the auspices of the International Centre for Theoretical Physics in Trieste, and elsewhere.

\bibliographystyle{kingbib}
\bibliography{R_Tutorial}

\end{document}
